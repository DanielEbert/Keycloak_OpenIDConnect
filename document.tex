\documentclass[12pt]{article}

\parindent0ex
\parskip 1ex plus 0.4ex minus 0.4ex

\usepackage[a4paper,vmargin=30mm,hmargin=25mm]{geometry}
\usepackage{fontspec}
\usepackage{polyglossia}
\setdefaultlanguage{german}

\usepackage{csquotes}
\usepackage[colorlinks=true,linkcolor=red]{hyperref}

\usepackage{color}
\usepackage{graphicx}
\usepackage{listings}

\usepackage[backend=biber]{biblatex}
%\bibliography{literatur}
\addbibresource{literatur.bib}

\title{Vorlage f√ºr das Konzept}
\author{Sebastian Scherer\\
	Daniel Ebert}
\date{}

\begin{document}
	\maketitle
	
\section{Summary}
	
We want to design and implementation a coverage guided fuzzer for testing client-side javascript running in headless chromium. Our fuzzer is written in python. pyppeteer \cite{6}, a high-level API to interact with applications running inside chromium, is used to forward generated inputs from the fuzzer to the client-side javascript and to forward exceptions and coverage information from chromium/client-side javascript to the fuzzer. Our fuzzer is a mutation based greybox fuzzer. Radamsa and mutation strategies from AFL are used to mutate inputs. We focus on finding bugs in the form of unhandeled exceptions, hangs, and excessive memory usage in the client-side javascript.

% say fuzzer finds automatically input fields and input to those

\section{Motivation}

In classic web applications, the server calculates and delivers an HTML document to the client. Since a few years there is a trend away from server-heavy code execution to client-heavy code execution. More code means more complexity, which leads to more bugs. The bugs on the client-side must be uncovered quickly and efficiently in order to enable a trouble-free process for the end user. Fuzzers can be used to find these bugs.

Coverage guided fuzzers for testing javascript like Jsfuzz \cite{1} \cite{2} exist already. However these fuzzers focus on testing nodejs packages \cite{1} \cite{2}, where javascript code is executed outside the browser. They thus differ from our fuzzer in many areas, especially in the communication between the fuzzer and the client-side javascript and in how coverage is calculated. There are monkey testing tools like gremlins.js \cite{3} and Webmonkey \cite{4} that test web application running inside browsers. These however focus on uncovering bugs via random actions instead of our coverage guided semi-random data approach \cite{3} \cite{4} \cite{5}.
% TODO: can optinally use the tools that acts as a server

\section{Fuzzer Workflow}

First the user chooses a target. The URL of the target website is passed to the fuzzer. pyppeteer repeatedly opens this website in headless chromium and navigates to the target location in an endless loop. The target location is the UI state where the fuzzer can type in the generated input. Especially in single-page applications, after opening the website the fuzzer might have to for example press buttons or log in to navigate to the target location. The fuzzer generates an input in every loop iteration. Inputs are generated by mutating randomly selected previous interesting inputs. Previous interesting inputs are inputs generated by the fuzzer that resulted in new code being executed in the client-side javascript. Our mutator is based on radamsa \cite{7} and extended by ideas from AFL. The latter were first mentioned in the AFL whitepaper \cite{8} and described later in more detail in a blog post \cite{9} from AFL's developer Michal Zalewski. Generated inputs are written into one or multiple input elements, for example text fields, via pyppeteer. An example target website can have 2 text fields, one for an email and one for a password. After writing the input, the user can optionally specify actions such as pressing a button or pressing enter. If the client-side javascript throws an unhandeled exception, uses excessive memory, or hangs, the loop iteration is abruptly stopped, the input and information about e.g. the exception is logged, and the fuzzer continues with the next loop iteration. A hang occurs when executing one input takes longer than a specified timeout. Logged inputs are deduplicated using stack hashing \cite{10}. Coverage information of every loop iteration is passed to the fuzzer from chromium via pyppeteer. The fuzzer uses this information to evaluate whether the input is interesting or not.

\section{Notizen, kann ignoriert werden TODO}
% use auto generated dictionary as mutation step? we probably can get the js code somehow

find paper where they talk about how to eval cov
talk about bug dedupl

can additionally create a flow diagram
optionally scheduling algos from one of the afl 2.0 fuzzers

cleanup includes potentially removing data or cookies from the browser's storage

heap usage via metrics? also stack usage?; unhandeled exceptions via emitters (there is a python package that pyppeteer uses)

	
\printbibliography 

\end{document}



% [1] https://github.com/fuzzitdev/jsfuzz
% [2] https://github.com/connor4312/js-fuzz
% [3] https://github.com/marmelab/gremlins.js/
% [4] https://github.com/Wildhoney/Webmonkey
% [5] https://stackoverflow.com/questions/10241957/difference-between-fuzz-testing-and-monkey-test
% [6] https://github.com/pyppeteer/pyppeteer
% [7] https://gitlab.com/akihe/radamsa
% [8] https://lcamtuf.coredump.cx/afl/technical_details.txt
% [9] https://lcamtuf.blogspot.com/2014/08/binary-fuzzing-strategies-what-works.html
% [10] https://arxiv.org/pdf/1812.00140.pdf



